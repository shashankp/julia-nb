{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pkg; Pkg.add.([\"Flux\", \"UnicodePlots\", \"Images\", \"ImageIO\", \"ImageMagick\", \"PlutoUI\", \"PyCall\", \"Conda\", \"BSON\"])\n",
    "\n",
    "using Flux\n",
    "using Flux.Data.MNIST\n",
    "using UnicodePlots\n",
    "using Images\n",
    "using ImageIO\n",
    "using ImageMagick\n",
    "using PlutoUI\n",
    "using PyCall\n",
    "using Conda\n",
    "using BSON: @save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conda.add(\"wandb\"; channel=\"conda-forge\")\n",
    "wandb = pyimport(\"wandb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = MNIST.labels()\n",
    "images = MNIST.images()\n",
    "\n",
    "n_inputs = unique(length.(images))[]\n",
    "n_outputs = length(unique(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess(img) = vec(Float64.(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function create_batch(r)\n",
    "    xs = [preprocess(img) for img in images[r]]\n",
    "    ys = [Flux.onehot(label, 0:9) for label in labels[r]]\n",
    "    return (Flux.batch(xs), Flux.batch(ys))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainbatch = create_batch(1:5000)\n",
    "testbatch = create_batch(5001:6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "train_loss = Float64[]\n",
    "test_loss = Float64[]\n",
    "\n",
    "wandb_run = wandb.init(project=\"mnist-flux\")\n",
    "function update_loss!()\n",
    "    trainL = L(trainbatch...)\n",
    "    testL = L(testbatch...)\n",
    "    push!(train_loss, trainL)\n",
    "    push!(test_loss, testL)\n",
    "    wandb.log(Dict(\"training_loss\"=>trainL))\n",
    "    wandb.log(Dict(\"testing_loss\"=>testL))    \n",
    "end\n",
    "\n",
    "model = Chain(\n",
    "    Dense(n_inputs, n_outputs, identity), \n",
    "    softmax\n",
    ")\n",
    "\n",
    "L(x,y) = Flux.crossentropy(model(x), y)\n",
    "opt = Flux.Optimise.Descent()\n",
    "@elapsed Flux.train!(L, \n",
    "                    params(model), \n",
    "                    Iterators.repeated(trainbatch, epochs), \n",
    "                    opt; \n",
    "                    cb=Flux.throttle(update_loss!, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineplot(1:length(train_loss), train_loss, title = \"train_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index = 50001\n",
    "#images[test_index]\n",
    "println(labels[test_index])\n",
    "findmax(model(preprocess(images[test_index]))) .- (0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@save \"mnist-flux.bson\" model\n",
    "wandb.save(\"mnist-flux.bson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.termwarn(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.1",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
